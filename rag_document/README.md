# ğŸ§  RAG-Document

Un sistema avanzato di Retrieval-Augmented Generation (RAG) progettato per gestire multipli flussi documentali. Il progetto espone un'architettura ibrida che supporta sia API REST tradizionali sia un **Server MCP (Model Context Protocol)** per l'interazione diretta con agenti AI autonomi.

## ğŸ—ï¸ Architettura del Sistema

<p align="center">
  <img src="img/img.png" width="400">
</p>

Il sistema Ã¨ orchestrato da un componente centrale (**Manager**) che gestisce il flusso di dati tra gli input, gli agenti e i database.

* **ğŸ¤– MCP Server:** Autentica e instrada le richieste di agenti multipli utilizzando un sistema di token verification.
* **ğŸ§  Core Manager:** Il "cervello" dell'applicazione. Crea e gestisce le pipeline, valuta le query e decide quale pipeline di retrieval o elaborazione attivare.
* **ğŸŒ API Server:** Espone gli endpoint tramite FastAPI per la creazione ed eliminazione dei vector store.
* **ğŸ—„ï¸ Neo4j Database:** Utilizza un database a grafi per memorizzare l'istantanea dei vector store creati.

---

## âœ¨ FunzionalitÃ  Principali

* Gestione di piÃ¹ richieste in parallelo da parte degli agenti.
* Sistema di cache intelligente per caricare in memoria solo i vector store piÃ¹ usati dagli agenti.
* Sistema di confronto tra varie tecniche di RAG avanzate, tra cui:
  * **Sparse (BM25)**
  * **Semantic**
  * **Hybrid Retriever**
  * **Contextual Header**
  * **Hierarchical Indices**
  * **Multi-Query RAG**
  * **Parent Document**
  * **Query Transformations**
  * **Relevant Segment Extraction**
  * **Reranking**

---

## ğŸ“ Struttura del Progetto

```text
rag_document/
â”œâ”€â”€ api/                # Endpoint FastAPI, schemi e router
â”œâ”€â”€ config/             # Impostazioni di sistema e configurazione logger
â”œâ”€â”€ db/                 # Connessioni e script di setup per Neo4j/Vector DB
â”œâ”€â”€ docs/               # Cartella di ingestione documenti (PDF, Docx, TXT)
â”œâ”€â”€ llm/                # Integrazioni con i provider LLM (Groq)
â”œâ”€â”€ mcp_server/         # Server Model Context Protocol e verifica token
â”œâ”€â”€ src/                # Core logic:
â”‚   â”œâ”€â”€ retrievers/     # Tutte le strategie di ricerca RAG sopra elencate
â”‚   â”œâ”€â”€ cache.py 
â”‚   â”œâ”€â”€ chuncker.py 
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ text_processor.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â””â”€â”€ manager.py
â””â”€â”€ test/                  # Script di benchmark per i retriever disponibili
â”‚   â”œâ”€â”€ results/           # Risultati dei test di comparione tra i retriever     
â”‚   â”œâ”€â”€ faqs.json          # Json con tutte le faq utilizzate nei test           
â”‚   â”œâ”€â”€ run_judge.py       # Codice per eseguire la valutazione LLM-AS-JUDGE delle risposte date dai retriever 
â”‚   â”œâ”€â”€ test_pipeline.py   # Codice per creare e confrontare i tempi di creazione delle pipeline per ogni retriever 
â”‚   â””â”€â”€ test_retriever.py  # Codice per effettuare le domande di test presenti in faqs ai retriver per poter confrontare la latenza 
```

---

## ğŸš€ Setup e Installazione

Puoi avviare il sistema RAG-Document in due modi: tramite **Docker** (metodo consigliato per test rapidi) o tramite un'**installazione locale** classica. Altrimenti Ã¨ possibile replicare i test eseguiti, ovvero confrontare tutti i retriver andando direttamente alla sezione Test e Benchmark, i risultati saranno presenti nella cartella test/results.

### 1ï¸âƒ£ Metodo Consigliato: Docker + MCP Inspector

Questo metodo genera un ambiente testabile dell'intero sistema caricando i documenti presenti nella cartella `docs/`.

Costruisci e avvia i container:

```bash
docker-compose up -d --build
```

In un nuovo terminale, avvia l'MCP Inspector per testare le richieste:

```bash
npx @modelcontextprotocol/inspector
```


### 2ï¸âƒ£ Metodo Locale: Installazione da sorgente

1. **Clona il repository ed entra nella cartella:**
```bash
cd rag-document
```


2. **Crea e attiva un ambiente virtuale:**
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```


3. **Installa le dipendenze:**
```bash
pip install torch --index-url [https://download.pytorch.org/whl/cpu](https://download.pytorch.org/whl/cpu)
pip install -r requirements.txt
python -m spacy download it_core_news_sm
python -c "import nltk; nltk.download('punkt_tab'); nltk.download('punkt'); nltk.download('stopwords')"
```


4. **Configura le variabili d'ambiente:**
```bash
cp .env.example .env
```

*Assicurati di inserire le tue chiavi API (es. GROQ) all'interno del file `.env`.*

5. **Fai partire il Sistema:**
```bash
python main.py
```

Una volta che hai fatto partire il sistema devi:
   1. Creare un db in Neo4j per tenere traccia dei vectorstore che crei.
   1. Aggiungere i tuoi documenti nella cartella docs/
   2. Creare un nuovo un vectorstore utilizzando le API costruito con i documenti che hai aggiunto.
   3. Collegarti al server MCP tramite l'inspector per effettuare le richieste al sistema(ricorda che ad ogni vectorstore creato Ã¨ collegata una chiave di autenticazione da dover fornire per connetterti al server mcp)


---

### Avvio dell'MCP Server in locale

Puoi avviare il server MCP in modalitÃ  HTTP o SSE:

```bash
python -m mcp_server.server                 # Default (SSE)
python -m mcp_server.server --transport sse
python -m mcp_server.server --transport http
```

Anche in questo caso, puoi usare l'Inspector aprendo un altro terminale:

```bash
npx @modelcontextprotocol/inspector
```

---

## ğŸ§ª Test e Benchmark

Ãˆ possibile riprodurre i test di confronto effettuati tra i vari retriever. Tutti i risultati (in formato `.xlsx`) verranno salvati automaticamente nella cartella `test/results/`.

**Testare la velocitÃ  di creazione delle pipeline di tutti i retriever:**

```bash
python -m test.test_pipeline
```

**Eseguire le domande di test per ogni retriever:**

```bash
python -m test.test_retriever
```

**Valutare la correttezza delle risposte (LLM-as-a-Judge):**

```bash
python -m test.run_judge
```

---